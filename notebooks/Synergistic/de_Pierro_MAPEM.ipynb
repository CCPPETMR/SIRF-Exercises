{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPEM de Pierro algorithm\n",
    "\n",
    "Authors: Kris Thielemans, Sam Ellis, Richard Brown  \n",
    "First version: 22nd of October 2019  \n",
    "Second version: 27th of October 2019\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019  University College London  \n",
    "Copyright 2019  King's College London  \n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with [PET/MAPEM](../PET/MAPEM.ipynb)...\n",
    "\n",
    "If you've already completed the PET component, you will have implemented a version of MAPEM. If you haven't, you'll probably want to give that a go first!\n",
    "\n",
    "This example extends upon the quadratic prior used in that notebook to use an anatomical prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All the normal imports and handy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "import numba\n",
    "#import scipy\n",
    "#from scipy import optimize\n",
    "import sirf.STIR as pet\n",
    "from sirf.Utilities import examples_data_path\n",
    "# plotting settings\n",
    "plt.ion() # interactive 'on' such that plots appear during loops\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "#%% some handy function definitions\n",
    "def imshow(image, limits=None, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image)\n",
    "    if limits is None:\n",
    "        limits = [image.min(), image.max()]\n",
    "                \n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV\"\"\"\n",
    "    filter = pet.TruncateToCylinderProcessor()\n",
    "    filter.apply(image)   \n",
    "\n",
    "#%% define a function for plotting images and the updates\n",
    "# This is the same function as in `ML_reconstruction`\n",
    "def plot_progress(all_images, title, subiterations, cmax):\n",
    "    if len(subiterations)==0:\n",
    "        num_subiters = all_images[0].shape[0]-1;\n",
    "        subiterations = range(1, num_subiters+1);\n",
    "    num_rows = len(all_images);\n",
    "    slice = 60\n",
    "    for iter in subiterations:\n",
    "        plt.figure(iter)\n",
    "        for r in range(num_rows):\n",
    "            plt.subplot(num_rows,2,2*r+1)\n",
    "            imshow(all_images[r][iter,slice,:,:], [0,cmax], '%s at %d' % (title[r],  iter))\n",
    "            plt.subplot(num_rows,2,2*r+2)\n",
    "            imshow(all_images[r][iter,slice,:,:]-all_images[r][iter-1,slice,:,:],[-cmax*.1,cmax*.1], 'update')\n",
    "        plt.show()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "To generate the data needed for this notebook, run the [generate_data](./generate_data.ipynb) notebook first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to correct directory\n",
    "os.chdir(\"/data\")\n",
    "\n",
    "#%% copy files to working folder and change directory to where the output files are\n",
    "shutil.rmtree('working_folder/dePierro_brainweb',True)\n",
    "shutil.copytree('brainweb','working_folder/dePierro_brainweb')\n",
    "os.chdir('working_folder/dePierro_brainweb')\n",
    "\n",
    "acquired_data = pet.AcquisitionData('subj_04_sino_noisy.hs')\n",
    "atten = pet.ImageData('subj_04_uMap.hv')\n",
    "\n",
    "# Anatomical image\n",
    "anatomical = pet.ImageData('subj_04_T1_tumour.hv') # could be MR_T2.nii or MR_PD.nii\n",
    "anatomical_arr = anatomical.as_array()\n",
    "\n",
    "#%%  create initial image\n",
    "init_image=atten.get_uniform_copy(atten.as_array().max()*.1)\n",
    "make_cylindrical_FOV(init_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code from first MAPEM notebook\n",
    "\n",
    "The following chunk of code is copied and pasted directly from the other notebook as a starting point. \n",
    "\n",
    "First, run the code chunk to get the results using the quadratic prior..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPEM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights as an array\n",
    "w=numpy.array([1.,0.,1.])\n",
    "# normalise to have sum 1\n",
    "w/=w.sum()\n",
    "\n",
    "# Define function for xreg\n",
    "@jit\n",
    "def compute_xreg(image_array):\n",
    "    sizes=image_array.shape\n",
    "    image_reg= image_array*0 # make a copy first. Will then change values\n",
    "    for z in range(0,sizes[0]):\n",
    "        for y in range(0,sizes[1]):\n",
    "            for x in range(1,sizes[2]-1): # ignore first and last pixel for simplicity\n",
    "                for dx in (-1,0,1):\n",
    "                    image_reg[z,y,x] += w[dx+1]/2*(image_array[z,y,x]+image_array[z,y,x+dx])\n",
    "            \n",
    "    return image_reg\n",
    "\n",
    "# define a function that computes the MAP-EM update\n",
    "@jit\n",
    "def compute_MAPEM_update(xEM,xreg, beta):\n",
    "    return (2*xEM)/(numpy.sqrt((1 - beta*xreg)**2 + 4*beta*xEM) + (1 - beta*xreg) + 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_fun(acquired_data, atten):\n",
    "    print('\\n------------- Setting up objective function')\n",
    "    #     #%% create objective function\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    am.set_num_tangential_LORs(5)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(atten, am)\n",
    "    asm_attn.set_up(acquired_data)\n",
    "    bin_eff = pet.AcquisitionData(acquired_data)\n",
    "    bin_eff.fill(1.0)\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    # Set sensitivity of the model and set up\n",
    "    am.set_acquisition_sensitivity(asm_attn)\n",
    "    am.set_up(acquired_data,atten);\n",
    "\n",
    "    #%% create objective function\n",
    "    obj_fun = pet.make_Poisson_loglikelihood(acquired_data)\n",
    "    obj_fun.set_acquisition_model(am)\n",
    "\n",
    "    print('\\n------------- Finished setting up objective function')\n",
    "    return obj_fun\n",
    "\n",
    "def get_reconstructor(num_subsets, num_subiters, obj_fun, init_image):\n",
    "    print('\\n------------- Setting up reconstructor') \n",
    "\n",
    "    #%% create OSEM reconstructor\n",
    "    OSEM_reconstructor = pet.OSMAPOSLReconstructor()\n",
    "    OSEM_reconstructor.set_objective_function(obj_fun)\n",
    "    OSEM_reconstructor.set_num_subsets(num_subsets)\n",
    "    OSEM_reconstructor.set_num_subiterations(num_subiters)\n",
    "\n",
    "    #%% initialise\n",
    "    OSEM_reconstructor.set_up(init_image)\n",
    "    \n",
    "    print('\\n------------- Finished setting up reconstructor')\n",
    "    return OSEM_reconstructor\n",
    "\n",
    "\n",
    "num_subsets = 21\n",
    "num_subiters = 1\n",
    "beta = 1\n",
    "\n",
    "# Use SSRB to create smaller sinogram to speed up calculations\n",
    "acquired_data=acquired_data.rebin(11,2,0)\n",
    "\n",
    "obj_fun = get_obj_fun(acquired_data, atten)\n",
    "OSEM_reconstructor = get_reconstructor(num_subsets,num_subiters, obj_fun, init_image)\n",
    "\n",
    "#%% do a loop, saving images as we go along\n",
    "current_image = init_image.clone()\n",
    "all_images = numpy.ndarray(shape=(num_subiters+1,) + current_image.as_array().shape );\n",
    "all_images[0,:,:,:] =  current_image.as_array();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iter in range(1, num_subiters+1):\n",
    "    print('\\n------------- Subiteration %d' % iter) \n",
    "    time_start_iter = time.time()\n",
    "    image_reg= compute_xreg(current_image.as_array()) # compute xreg\n",
    "    \n",
    "\n",
    "    time_compute_xreg = time.time()\n",
    "    print(\"time for compute xreg: %d\" % (time_compute_xreg - time_start_iter))\n",
    "    OSEM_reconstructor.update(current_image); # compute EM update\n",
    "    time_osem_update = time.time()\n",
    "    print(\"time osem update: %d\" % (time_osem_update - time_compute_xreg))\n",
    "    image_EM=current_image.as_array() # get xEM as a numpy array\n",
    "    time_as_array = time.time()\n",
    "    print(\"time as_array: %d\" % (time_as_array - time_osem_update))\n",
    "    updated = compute_MAPEM_update(image_EM, image_reg, beta) # compute new update\n",
    "    time_mapem_update = time.time()\n",
    "    print(\"time mapem update: %d\" % (time_mapem_update - time_as_array))\n",
    "    current_image.fill(updated) # store for next iteration\n",
    "    time_fill = time.time()\n",
    "    print(\"time fill: %d\" % (time_fill - time_mapem_update) )\n",
    "    all_images[iter,:,:,:] =  updated; # save for plotting later on\n",
    "\n",
    "# # #%% now call this function to see how we went along\n",
    "# # subiterations = (1,2,4,8,16,32,42);\n",
    "# # plot_progress([all_images], ['MAP-OSEM'],subiterations, all_images.max()*0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement de Pierro regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePierroUpdate(xEM, imageReg, beta, sensImg):\n",
    "    \n",
    "    delta = 1e-6*abs(sensImg).max()\n",
    "    sensImg[sensImg < delta] = delta # avoid division by zero\n",
    "    beta_j = beta/sensImg\n",
    "    return (2*xEM)/(numpy.sqrt((1 - beta_j*imageReg)**2 + 4*beta_j*xEM) + (1 - beta_j*imageReg) + 0.00001)\n",
    "\n",
    "def dePierroReg(image,weights,nhoodIndVec):\n",
    "    \n",
    "    # vectorise image for indexing \n",
    "    imageVec = image.reshape(-1,order='F')\n",
    "        \n",
    "    # retrieve voxel intensities for neighbourhoods \n",
    "    resultVec = imageVec[nhoodIndVec]\n",
    "    result = resultVec.reshape(weights.shape,order='F')\n",
    "    \n",
    "    # compute xreg\n",
    "    imageReg = 0.5*numpy.sum(weights*(result + image.reshape(-1,1,order='F')),axis=1)\n",
    "    imageReg = imageReg.reshape(imSize,order='F')\n",
    "    \n",
    "    return imageReg\n",
    "\n",
    "# old version\n",
    "def dePierroReg2Arg(image,weights):\n",
    "    \n",
    "    # get size and vectorise image for indexing \n",
    "    imSize = image.shape\n",
    "    imageVec = image.reshape(-1,1,order='F').flatten('F')\n",
    "    \n",
    "    # get the neigbourhoods of each voxel\n",
    "    weightsSize = weights.shape\n",
    "    w = int(round(weightsSize[1]**(1.0/3))) # side length of neighbourhood\n",
    "    nhoodInd    = neighbourExtract(imSize,w)\n",
    "    nhoodIndVec = nhoodInd.reshape(-1,order='F')\n",
    "    \n",
    "    # retrieve voxel intensities for neighbourhoods \n",
    "    resultVec = numpy.float32(imageVec[nhoodIndVec])\n",
    "    result = resultVec.reshape(nhoodInd.shape,order='F')\n",
    "    \n",
    "    # compute xreg\n",
    "    try:\n",
    "        imageReg = 0.5*numpy.sum(weights*(result + image.reshape(-1,1,order='F')),axis=1)\n",
    "    except:\n",
    "        tmpVar = 1;    \n",
    "    imageReg = imageReg.reshape(imSize,order='F')\n",
    "    \n",
    "    return imageReg\n",
    "\n",
    "def compute_nhoodIndVec(image,weights):\n",
    "    # get the neigbourhoods of each voxel\n",
    "    weightsSize = weights.shape\n",
    "    w = int(round(weightsSize[1]**(1.0/3))) # side length of neighbourhood\n",
    "    nhoodInd    = neighbourExtract(image.shape,w)\n",
    "    return nhoodInd.reshape(-1,order='F')\n",
    "    \n",
    "def neighbourExtract(imageSize,w):\n",
    "    # Adapted from Prior class        \n",
    "    n = imageSize[0]\n",
    "    m = imageSize[1]\n",
    "    h = imageSize[2]\n",
    "    wlen = 2*numpy.floor(w/2)\n",
    "    widx = xidx = yidx = numpy.arange(-wlen/2,wlen/2+1)\n",
    "\n",
    "    if h==1:\n",
    "        zidx = [0]\n",
    "        nN = w*w\n",
    "    else:\n",
    "        zidx = widx\n",
    "        nN = w*w*w\n",
    "        \n",
    "    Y,X,Z = numpy.meshgrid(numpy.arange(0,m), numpy.arange(0,n), numpy.arange(0,h))                \n",
    "    N = numpy.zeros([n*m*h, nN],dtype='int32')\n",
    "    l = 0\n",
    "    for x in xidx:\n",
    "        Xnew = setBoundary(X + x,n)\n",
    "        for y in yidx:\n",
    "            Ynew = setBoundary(Y + y,m)\n",
    "            for z in zidx:\n",
    "                Znew = setBoundary(Z + z,h)\n",
    "                N[:,l] = ((Xnew + (Ynew)*n + (Znew)*n*m)).reshape(-1,1).flatten('F')\n",
    "                l += 1\n",
    "    return N\n",
    "\n",
    "def setBoundary(X,n):\n",
    "    # Boundary conditions for neighbourExtract\n",
    "    # Adapted from Prior class\n",
    "    idx = X<0\n",
    "    X[idx] = X[idx] + n\n",
    "    idx = X>n-1\n",
    "    X[idx] = X[idx] - n\n",
    "    return X.flatten('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic():\n",
    "    #Homemade version of matlab tic and toc functions\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_`tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    return time.time() - startTime_for_tictoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPEM input data and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSEM_reconstructor = get_reconstructor(num_subsets,num_subiters, obj_fun, init_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_image = obj_fun.get_subset_sensitivity(0)*num_subsets\n",
    "beta = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Prior for computing Bowsher weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sirf.contrib.kcl.Prior as pr\n",
    "myPrior = pr.Prior(anatomical_arr.shape)\n",
    "weights = myPrior.BowshserWeights(anatomical_arr,7)\n",
    "weights = numpy.float32(weights/7.0)\n",
    "if (numpy.abs(numpy.sum(weights,axis=1)-1)>1.0e-6).any():\n",
    "    raise ValueError(\"Weights should sum to 1 for each voxel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of the neighbourhood\n",
    "nhoodIndVec=compute_nhoodIndVec(image,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# illustrate that only a few of the weights in the neighbourhood are kept\n",
    "# (taking an arbitrary voxel)\n",
    "weights[500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first run a few OSEM subiterations to get a reasonable image\n",
    "OSEM_reconstructor.set_num_subiterations(12)\n",
    "osem_init_image = init_image.clone()\n",
    "OSEM_reconstructor.reconstruct(osem_init_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subiters=42\n",
    "beta=.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowsher=current_image.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable this to use uniform weights\n",
    "# weights[:]=1/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_image=osem_init_image\n",
    "all_images_deP = numpy.ndarray(shape=(num_subiters+1,) + current_image.as_array().shape );\n",
    "all_images_deP[0,:,:,:] =  current_image.as_array();\n",
    "sensitivity_image = obj_fun.get_subset_sensitivity(0).as_array()\n",
    "for iter in range(1, num_subiters+1):\n",
    "    print('\\n------------- Subiteration %d' % iter) \n",
    "    \n",
    "    # image_reg= compute_xreg(current_image.as_array()) # compute xreg\n",
    "    image_reg= dePierroReg(current_image.as_array(),weights,nhoodIndVec) # compute xreg\n",
    "    OSEM_reconstructor.update(current_image); # compute EM update\n",
    "    image_EM=current_image.as_array() # get xEM as a numpy array\n",
    "    # updated = compute_MAPEM_update(image_EM, image_reg, beta) # compute new update\n",
    "    updated = dePierroUpdate(image_EM, image_reg, beta, sensitivity_image) # compute new update\n",
    "    current_image.fill(updated) # store for next iteration\n",
    "    all_images_deP[iter,:,:,:] =  updated; # save for plotting later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=current_image.as_array()\n",
    "slice = array.shape[0]//2\n",
    "cmax=array.max()*.9\n",
    "imshow(array[slice,:,:],[0,cmax],'MAP-OSEM');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run OSEM for the same number of subiterations for comparison\n",
    "OSEM_reconstructor.set_num_subiterations(num_subiters)\n",
    "osem_image = osem_init_image.clone()\n",
    "OSEM_reconstructor.reconstruct(osem_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(osem_image.as_array()[slice,:,:],[0,cmax],'OSEM');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% now call this function to see how we went along\n",
    "plot_progress([all_images_deP], ['MAP-OSEM'],numpy.arange(10,num_subiters), cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
