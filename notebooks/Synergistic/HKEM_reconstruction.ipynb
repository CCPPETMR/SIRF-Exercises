{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Demonstration of the Hybrid Kernelised Expaction Maximisation (HKEM) reconstruction with SIRF\n",
    "This demonstration shows how to use HKEM and investigate the role of each kernel parameter in edge preservation and noise suppression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Daniel Deidda, Kris Thielemans and Evgueni Ovtchinnikov, Richard Brown  \n",
    "First version: 30th of September 2019  \n",
    "Second Version: 6th of November 2019\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019  National Physical Laboratory\n",
    "Copyright 2019  Rutherford Appleton Laboratory STFC  \n",
    "Copyright 2019  University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "N.B.: You need to have run the [brainweb](./BrainWeb.ipynb) notebook first.\n",
    "\n",
    "## Further reading!\n",
    "\n",
    "Lastly, if you wish to read about HKEM, check out the original article by D. Deidda et al. (2019), available here: https://iopscience.iop.org/article/10.1088/1361-6420/ab013f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make sure figures appears inline and animations works\n",
    "%matplotlib notebook\n",
    "\n",
    "# Setup the working directory for the notebook\n",
    "import notebook_setup\n",
    "from sirf_exercises import cd_to_working_dir\n",
    "cd_to_working_dir('Synergistic', 'HKEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import string\n",
    "#import scipy\n",
    "#from scipy import optimize\n",
    "import sirf.STIR as pet\n",
    "from sirf_exercises import exercises_data_path\n",
    "\n",
    "brainweb_sim_data_path = exercises_data_path('working_folder', 'Synergistic', 'BrainWeb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% some handy function definitions\n",
    "def imshow_hot(image, limits, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image, cmap=\"hot\")\n",
    "    if len(limits)==0:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def imshow(image, limits, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image)\n",
    "    if len(limits)==0:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def imshow_gray(image, limits, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image, cmap=\"gray\")\n",
    "    if len(limits)==0:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def make_positive(image_array):\n",
    "    \"\"\"truncate any negatives to zero\"\"\"\n",
    "    image_array[image_array<0] = 0\n",
    "    return image_array\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV\"\"\"\n",
    "    filter = pet.TruncateToCylinderProcessor()\n",
    "    filter.apply(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some data and set some values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data we generated previously in BrainWeb.ipynb\n",
    "sino = pet.AcquisitionData(os.path.join(brainweb_sim_data_path, 'FDG_tumour_sino_noisy.hs'))\n",
    "\n",
    "#%% the following multiplication is just in case the noise sinogram has a different scale from the noiseless\n",
    "# you can remove it in a real data situation\n",
    "sino = sino*1000\n",
    "\n",
    "atten = pet.ImageData(os.path.join(brainweb_sim_data_path, 'uMap_small.hv'))\n",
    "\n",
    "# Anatomical image\n",
    "anatomical = pet.ImageData(os.path.join(brainweb_sim_data_path, 'T2_small.hv'))\n",
    "anatomical.fill(make_positive(anatomical.as_array()))\n",
    "\n",
    "#%%  create initial image\n",
    "init_image=atten.get_uniform_copy(atten.as_array().max()*.1)\n",
    "make_cylindrical_FOV(init_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pet.ImageData(os.path.join(brainweb_sim_data_path, 'FDG_tumour.hv'))\n",
    "image_array = image.as_array()\n",
    "#%% save max for future displays\n",
    "cmax = image_array.max()*.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show anatomical image and true image\n",
    "anatomical_array=anatomical.as_array()\n",
    "atten_array=atten.as_array()\n",
    "im_slice = 62 #atten_array.shape[0]//2\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "imshow_gray(anatomical_array[im_slice,:,:,], [0,220],'Anatomical image')\n",
    "plt.subplot(1,2,2)\n",
    "imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the acquisition model and objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SSRB to create smaller sinogram to speed up calculations if needed\n",
    "# if you want to make things faster you can rebin your data by compressing axial and view bins\n",
    "# this will affect the quality of the reconstructed images. See help(full_sino.rebin)\n",
    "# if you have enough computational power you can try unsetting max_in_segment_num_to_process\n",
    "sino = full_sino.rebin(1, num_views_to_combine=1,max_in_segment_num_to_process=0,do_normalisation=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% create acquisition model\n",
    "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "am.set_num_tangential_LORs(5)\n",
    "\n",
    "# Set up sensitivity due to attenuation\n",
    "asm_attn = pet.AcquisitionSensitivityModel(atten, am)\n",
    "asm_attn.set_up(sino)\n",
    "bin_eff = pet.AcquisitionData(sino)\n",
    "bin_eff.fill(1.0)\n",
    "asm_attn.unnormalise(bin_eff)\n",
    "asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "# Set sensitivity of the model and set up\n",
    "am.set_acquisition_sensitivity(asm_attn)\n",
    "am.set_up(sino,atten)\n",
    "\n",
    "#%% create objective function\n",
    "obj_fun = pet.make_Poisson_loglikelihood(sino)\n",
    "obj_fun.set_acquisition_model(am)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  create KOSMAPOSL reconstructor\n",
    "This implements the Ordered Subsets HKEM\n",
    "In this section we define all parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = pet.KOSMAPOSLReconstructor()\n",
    "recon.set_objective_function(obj_fun)\n",
    "\n",
    "recon.set_input(sino)\n",
    "\n",
    "recon.set_anatomical_prior(anatomical)\n",
    "recon.set_num_non_zero_features(1)\n",
    "recon.set_num_subsets(21)\n",
    "recon.set_num_subiterations(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter sigma_m (MR edge preservation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1m_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_num_neighbours(3)\n",
    "recon.set_sigma_p(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "sigma_m={0.05, 0.2, 1}\n",
    "ii=0\n",
    "for i in sigma_m:\n",
    "\n",
    "    H1m_reconstructed_image.append(init_image.clone())\n",
    "    \n",
    "    recon.set_sigma_m(i)\n",
    "\n",
    "#   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1m_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1m_reconstructed_image[ii])\n",
    "\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% bitmap display of images\n",
    "# define lists\n",
    "H1m_reconstructed_array = []\n",
    "H1m_error_array = []\n",
    "\n",
    "ii=0\n",
    "\n",
    "for i in sigma_m:\n",
    "\n",
    "    H1m_reconstructed_array.append(H1m_reconstructed_image[ii].as_array())\n",
    "    H1m_error_array.append(image_array - H1m_reconstructed_array[ii])\n",
    "    \n",
    "  \n",
    "    j=\"{}\".format(i)\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1m_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'sigma_m='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1m_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter sigma_p (PET edge preservation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1p_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_num_neighbours(3)\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "sigma_p={0.05, 2}\n",
    "ii=0\n",
    "for i in sigma_p:\n",
    "\n",
    "    H1p_reconstructed_image.append(init_image.clone())\n",
    "\n",
    "    recon.set_sigma_p(i)\n",
    "#   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1p_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1p_reconstructed_image[ii])\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1p_reconstructed_image.append(H1p_reconstructed_image[1])\n",
    "#%% bitmap display of images\n",
    "# define lists\n",
    "H1p_reconstructed_array = []\n",
    "H1p_error_array = []\n",
    "ii=0\n",
    "sigma_p={0.05, 2,0.2}\n",
    "for i in sigma_p:\n",
    "\n",
    "    j=\"{}\".format(i)\n",
    "\n",
    "    H1p_reconstructed_array.append(H1p_reconstructed_image[ii].as_array())\n",
    "\n",
    "    H1p_error_array.append(image_array - H1p_reconstructed_array[ii])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1p_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'sigma_p='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1p_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter sigma_d (smoothing, depends on the voxel size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1d_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_num_neighbours(3)\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_p(0.2)\n",
    "\n",
    "sigma_dm={0.5, 1}\n",
    "ii=0\n",
    "for i in sigma_dm:\n",
    "\n",
    "    H1d_reconstructed_image.append(init_image.clone())\n",
    "\n",
    "    recon.set_sigma_dp(i)\n",
    "    recon.set_sigma_dm(i)\n",
    "\n",
    "   #   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1d_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1d_reconstructed_image[ii])\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1d_reconstructed_image.append(H1m_reconstructed_image[1])\n",
    "#%% bitmap display of images\n",
    "# define lists\n",
    "H1d_reconstructed_array = []\n",
    "H1d_error_array = []\n",
    "ii=0\n",
    "sigma_dm={0.5, 1, 5}\n",
    "for i in sigma_dm:\n",
    "\n",
    "    j=\"{}\".format(i)\n",
    "\n",
    "    H1d_reconstructed_array.append(H1d_reconstructed_image[ii].as_array())\n",
    "\n",
    "#   anatomical_image_array = anatomical_image.as_array()\n",
    "    H1d_error_array.append(image_array - H1d_reconstructed_array[ii])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1d_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'sigma_dm='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1d_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study parameter \"neighbourhood size\", n\n",
    "try to rebin the data if it is too slow (sino.rebin(segments, views) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct the image \n",
    "H1n_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_p(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "n={1, 5}\n",
    "ii=0\n",
    "for i in n:\n",
    "\n",
    "    H1n_reconstructed_image.append(init_image.clone())\n",
    "\n",
    "    recon.set_num_neighbours(i)\n",
    "\n",
    "#   set up the reconstructor\n",
    "    recon.set_hybrid(True)\n",
    "    recon.set_up(H1n_reconstructed_image[ii])\n",
    "    recon.reconstruct(H1n_reconstructed_image[ii])\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1n_reconstructed_image.pop(1)\n",
    "H1n_reconstructed_image.append(H1m_reconstructed_image[1])\n",
    "#%% bitmap display of images\n",
    "# define lists\n",
    "\n",
    "H1n_reconstructed_array = []\n",
    "H1n_error_array = []\n",
    "ii=0\n",
    "n={1, 5, 3}\n",
    "for i in n:\n",
    "\n",
    "    j=\"{}\".format(i)\n",
    "    \n",
    "    H1n_reconstructed_array.append(H1n_reconstructed_image[ii].as_array())\n",
    "\n",
    "#   anatomical_image_array = anatomical_image.as_array()\n",
    "    H1n_error_array.append(image_array - H1n_reconstructed_array[ii])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    imshow_hot(image_array[im_slice,:,:,], [0,cmax*2],'True image')\n",
    "    plt.subplot(1,3,2)\n",
    "    imshow_hot(H1n_reconstructed_array[ii][im_slice,:,:,], [0,cmax*2], 'HKEM, N='+j)\n",
    "    plt.subplot(1,3,3)\n",
    "    imshow(H1n_error_array[ii][im_slice,:,:,], [-cmax*0.5,cmax*0.5], 'HKEM error')\n",
    "\n",
    "    ii=ii+1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct KEM By setting hybrid to false\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HKEM image is: H1n_reconstructed_array\n",
    "    \n",
    "    #%% reconstruct the image \n",
    "H0_reconstructed_image = [] \n",
    "\n",
    "#fix other parameters\n",
    "recon.set_sigma_m(0.2)\n",
    "recon.set_sigma_p(0.2)\n",
    "recon.set_sigma_dm(5.0)\n",
    "recon.set_sigma_dp(5.0)\n",
    "\n",
    "H0_reconstructed_image.append(init_image.clone())\n",
    "recon.set_num_neighbours(5)\n",
    "\n",
    "#   set up the reconstructor\n",
    "recon.set_hybrid(False)\n",
    "recon.set_up(H0_reconstructed_image[0])\n",
    "recon.reconstruct(H0_reconstructed_image[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare HKEM and KEM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_reconstructed_array= H0n_reconstructed_image[0].as_array()\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "imshow_hot(H0_reconstructed_array[im_slice,:,:,], [0,cmax*2.], 'KEM')\n",
    "plt.subplot(1,2,2)\n",
    "imshow_hot(H1n_reconstructed_array[2][im_slice,:,:,], [0,cmax*2.], 'HKEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) what difference can you see when you change each parameter? and between HKEM and KEM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create misalignment between Anatomical image and PET image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you can create misalignment by shifting or rotation the anatomical image like in the notebook \"BrainWeb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set KOSMAPOSL reconstructor using the new anatomical image and reconstruct as above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot images: Describe what was the effect of this misalignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run a OSEM reconstruction and align the anatomical image from the previous exercise with the OSEM image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use what you learned in the PET reconstruction notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Similar exercise could be done with other type of anatomical information. You could have a look at the de_Pierro_MAPEM notebook and repeat these exrcises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
