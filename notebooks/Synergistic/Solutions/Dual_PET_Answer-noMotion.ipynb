{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual PET tracer de Pierro no motion\n",
    "\n",
    "Authors: Kris Thielemans, Sam Ellis, Richard Brown, Casper da Costa-Luis  \n",
    "First version: 2nd of November 2019\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF)  \n",
    "Copyright 2019  University College London  \n",
    "Copyright 2019  King's College London  \n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The challenge!\n",
    "\n",
    "This notebook is an open-ended look into using de Pierro MAPEM to reconstruct dual-PET acquisitions.\n",
    "\n",
    "- Imagine two different scans (FDG and amyloid) were performed in a short space of time on a single patient. \n",
    "- Your task is to implement an alternating reconstruction of the two scans using de Pierro's MAPEM algorithm!\n",
    "\n",
    "## Suggested workflow - no motion\n",
    "\n",
    "- Inspire yourself from [de_Pierro_MAPEM.ipynb](de_Pierro_MAPEM.ipynb), in which Bowsher weights are calculated on some known side information.\n",
    "- Now, imagine that the side information is evolving with our image estimate\n",
    "- We'll probably want to perform an update on one of our images (image A)\n",
    "- Then recalculate the Bowsher weights of the second image (image B) with our newly-update image A\n",
    "- Then perform a normal de Pierro update on image B\n",
    "- Then recalculate the Bowsher weights of image A using our newly-updated image B\n",
    "\n",
    "### But what about motion?\n",
    "\n",
    "It's possible that there's motion between the two images since they were acquired at different times. Once you've got everything working for dual PET reconstructions, it's time to add motion in just to complicate things!\n",
    "\n",
    "- Imagine two different scans (FDG and amyloid) were performed in a short space of time on a single patient. \n",
    "- Your task is to implement an alternating reconstruction of the two scans using de Pierro's MAPEM algorithm!\n",
    "- Bear in mind that the two scans weren't performed at the same time, so the patient's head isn't necessarily in the same place...\n",
    "\n",
    "## Suggested workflow - motion\n",
    "\n",
    "1. Since we can't be sure of patient position, you should probably reconstruct each image individually \n",
    "2. Then register them\n",
    "3. Then modify your non-motion case, such that you resample each image into the others' space before calculating the Bowsher weights\n",
    "\n",
    "Hints:\n",
    "- For an implementation of de Pierro MAPEM, checkout the [de_Pierro_MAPEM.ipynb](de_Pierro_MAPEM.ipynb) notebook.\n",
    "- To go faster, rebin your sinograms (as per [de_Pierro_MAPEM.ipynb](de_Pierro_MAPEM.ipynb)!\n",
    "- For registration and resampling, check out the [../Reg/sirf_registration.ipynb](../Reg/sirf_registration.ipynb) notebook. \n",
    "\n",
    "### One final word\n",
    "\n",
    "We've given you some pointers down below that you can fill bit by bit. The sections marked with astrisks won't be needed until you implement the motion case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0a. Some includes and imshow-esque functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the normal stuff you've already seen\n",
    "import notebook_setup\n",
    "\n",
    "#%% Initial imports etc\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from tqdm.auto import tqdm, trange\n",
    "import time\n",
    "import sirf.STIR as pet\n",
    "from sirf_exercises import exercises_data_path\n",
    "import sirf.Reg as Reg\n",
    "import sirf.contrib.kcl.Prior as pr\n",
    "\n",
    "# plotting settings\n",
    "plt.ion() # interactive 'on' such that plots appear during loops\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "#%% some handy function definitions\n",
    "def imshow(image, limits=None, title=''):\n",
    "    \"\"\"Usage: imshow(image, [min,max], title)\"\"\"\n",
    "    plt.title(title)\n",
    "    bitmap = plt.imshow(image)\n",
    "    if limits is None:\n",
    "        limits = [image.min(), image.max()]\n",
    "\n",
    "    plt.clim(limits[0], limits[1])\n",
    "    plt.colorbar(shrink=.6)\n",
    "    plt.axis('off')\n",
    "    return bitmap\n",
    "\n",
    "def make_cylindrical_FOV(image):\n",
    "    \"\"\"truncate to cylindrical FOV\"\"\"\n",
    "    filter = pet.TruncateToCylinderProcessor()\n",
    "    filter.apply(image)   \n",
    "\n",
    "#%% define a function for plotting images and the updates\n",
    "# This is the same function as in `ML_reconstruction`\n",
    "def plot_progress(all_images1,all_images2, title1, title2, subiterations, cmax):\n",
    "    if len(subiterations)==0:\n",
    "        num_subiters = all_images1[0].shape[0]-1\n",
    "        subiterations = range(1, num_subiters+1);\n",
    "    num_rows = len(all_images1);\n",
    "    slice = 60\n",
    "    for iter in subiterations:\n",
    "        plt.figure()\n",
    "        for r in range(num_rows):\n",
    "            plt.subplot(num_rows,2,2*r+1)\n",
    "            imshow(all_images1[r][iter,slice,:,:], [0,cmax], '%s at %d' % (title1[r],  iter))\n",
    "            plt.subplot(num_rows,2,2*r+2)\n",
    "            imshow(all_images2[r][iter,slice,:,:], [0,cmax], '%s at %d' % (title2[r],  iter))\n",
    "        plt.show();  \n",
    "\n",
    "def subplot_(idx,vol,title,clims=None,cmap=\"viridis\"):\n",
    "    plt.subplot(*idx)\n",
    "    plt.imshow(vol,cmap=cmap)\n",
    "    if not clims is None:\n",
    "        plt.clim(clims)\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0b. Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get to correct directory\n",
    "os.chdir(exercises_data_path('Synergistic'))\n",
    "\n",
    "# copy files to working folder and change directory to where the output files are\n",
    "shutil.rmtree('working_folder/dual_PET_noMotion',True)\n",
    "shutil.copytree('brainweb','working_folder/dual_PET_noMotion')\n",
    "os.chdir('working_folder/dual_PET_noMotion')\n",
    "\n",
    "fname_FDG_sino = 'FDG_sino_noisy.hs'\n",
    "fname_FDG_uMap = 'uMap_small.hv'\n",
    "# No motion filenames\n",
    "fname_amyl_sino = 'amyl_sino_noisy.hs'\n",
    "fname_amyl_uMap = 'uMap_small.hv'\n",
    "# Motion filenames\n",
    "# fname_amyl_sino = 'amyl_sino_noisy_misaligned.hs'\n",
    "# fname_amyl_uMap = 'uMap_misaligned.hv'\n",
    "\n",
    "full_fdg_sino = pet.AcquisitionData(fname_FDG_sino)\n",
    "fdg_sino = full_fdg_sino.rebin(3)\n",
    "fdg_uMap = pet.ImageData(fname_FDG_uMap)\n",
    "\n",
    "full_amyl_sino = pet.AcquisitionData(fname_amyl_sino)\n",
    "amyl_sino = full_amyl_sino.rebin(3)\n",
    "amyl_uMap = pet.ImageData(fname_amyl_uMap)\n",
    "\n",
    "fdg_init_image=fdg_uMap.get_uniform_copy(fdg_uMap.as_array().max()*.1)\n",
    "make_cylindrical_FOV(fdg_init_image)\n",
    "\n",
    "amyl_init_image=amyl_uMap.get_uniform_copy(amyl_uMap.as_array().max()*.1)\n",
    "make_cylindrical_FOV(amyl_init_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0c. Set up normal reconstruction stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to set up objective function and OSEM recontsructors\n",
    "def get_obj_fun(acquired_data, atten):\n",
    "    print('\\n------------- Setting up objective function')\n",
    "    #     #%% create objective function\n",
    "    #%% create acquisition model\n",
    "    am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "    am.set_num_tangential_LORs(5)\n",
    "\n",
    "    # Set up sensitivity due to attenuation\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(atten, am)\n",
    "    asm_attn.set_up(acquired_data)\n",
    "    bin_eff = pet.AcquisitionData(acquired_data)\n",
    "    bin_eff.fill(1.0)\n",
    "    asm_attn.unnormalise(bin_eff)\n",
    "    asm_attn = pet.AcquisitionSensitivityModel(bin_eff)\n",
    "\n",
    "    # Set sensitivity of the model and set up\n",
    "    am.set_acquisition_sensitivity(asm_attn)\n",
    "    am.set_up(acquired_data,atten);\n",
    "\n",
    "    #%% create objective function\n",
    "    obj_fun = pet.make_Poisson_loglikelihood(acquired_data)\n",
    "    obj_fun.set_acquisition_model(am)\n",
    "\n",
    "    print('\\n------------- Finished setting up objective function')\n",
    "    return obj_fun\n",
    "\n",
    "def get_reconstructor(num_subsets, num_subiters, obj_fun, init_image):\n",
    "    print('\\n------------- Setting up reconstructor') \n",
    "\n",
    "    #%% create OSEM reconstructor\n",
    "    OSEM_reconstructor = pet.OSMAPOSLReconstructor()\n",
    "    OSEM_reconstructor.set_objective_function(obj_fun)\n",
    "    OSEM_reconstructor.set_num_subsets(num_subsets)\n",
    "    OSEM_reconstructor.set_num_subiterations(num_subiters)\n",
    "\n",
    "    #%% initialise\n",
    "    OSEM_reconstructor.set_up(init_image)\n",
    "\n",
    "    print('\\n------------- Finished setting up reconstructor')\n",
    "    return OSEM_reconstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subsets = 21\n",
    "num_subiters = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Two individual reconstructions *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Register images *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. A resample function? *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about a bit of code here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Maybe some de Pierro functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A pinch more code here\n",
    "def dePierroReg(image,weights,nhoodIndVec):\n",
    "    \"\"\"Get the de Pierro regularisation image\"\"\"\n",
    "    imSize = image.shape\n",
    "\n",
    "    # vectorise image for indexing \n",
    "    imageVec = image.reshape(-1,order='F')\n",
    "\n",
    "    # retrieve voxel intensities for neighbourhoods \n",
    "    resultVec = imageVec[nhoodIndVec]\n",
    "    result = resultVec.reshape(weights.shape,order='F')\n",
    "\n",
    "    # compute xreg\n",
    "    imageReg = 0.5*numpy.sum(weights*(result + image.reshape(-1,1,order='F')),axis=1)\n",
    "    imageReg = imageReg.reshape(imSize,order='F')\n",
    "\n",
    "    return imageReg\n",
    "\n",
    "def compute_nhoodIndVec(image,weights):\n",
    "    \"\"\"Get the neigbourhoods of each voxel\"\"\"\n",
    "    weightsSize = weights.shape\n",
    "    w = int(round(weightsSize[1]**(1.0/3))) # side length of neighbourhood\n",
    "    nhoodInd    = neighbourExtract(image.shape,w)\n",
    "    return nhoodInd.reshape(-1,order='F')\n",
    "\n",
    "def neighbourExtract(imageSize,w):\n",
    "    \"\"\"Adapted from Prior class\"\"\"\n",
    "    n = imageSize[0]\n",
    "    m = imageSize[1]\n",
    "    h = imageSize[2]\n",
    "    wlen = 2*numpy.floor(w/2)\n",
    "    widx = xidx = yidx = numpy.arange(-wlen/2,wlen/2+1)\n",
    "\n",
    "    if h==1:\n",
    "        zidx = [0]\n",
    "        nN = w*w\n",
    "    else:\n",
    "        zidx = widx\n",
    "        nN = w*w*w\n",
    "\n",
    "    Y,X,Z = numpy.meshgrid(numpy.arange(0,m), numpy.arange(0,n), numpy.arange(0,h))                \n",
    "    N = numpy.zeros([n*m*h, nN],dtype='int32')\n",
    "    l = 0\n",
    "    for x in xidx:\n",
    "        Xnew = setBoundary(X + x,n)\n",
    "        for y in yidx:\n",
    "            Ynew = setBoundary(Y + y,m)\n",
    "            for z in zidx:\n",
    "                Znew = setBoundary(Z + z,h)\n",
    "                N[:,l] = ((Xnew + (Ynew)*n + (Znew)*n*m)).reshape(-1,1).flatten('F')\n",
    "                l += 1\n",
    "    return N\n",
    "\n",
    "def setBoundary(X,n):\n",
    "    \"\"\"Boundary conditions for neighbourExtract.\n",
    "    Adapted from Prior class\"\"\"\n",
    "    idx = X<0\n",
    "    X[idx] = X[idx] + n\n",
    "    idx = X>n-1\n",
    "    X[idx] = X[idx] - n\n",
    "    return X.flatten('F')\n",
    "\n",
    "def dePierroUpdate(xEM, imageReg, beta):\n",
    "    \"\"\"Update the image based on the de Pierro regularisation image\"\"\"\n",
    "    return (2*xEM)/(((1 - beta*imageReg)**2 + 4*beta*xEM)**0.5 + (1 - beta*imageReg) + 0.00001)\n",
    "\n",
    "\n",
    "fdg_prior = pr.Prior(fdg_init_image.shape)\n",
    "amyl_prior = pr.Prior(amyl_init_image.shape)\n",
    "\n",
    "num_bowsher_neighbours = 7\n",
    "\n",
    "def update_bowsher_weights(prior,side_image,num_bowsher_neighbours):\n",
    "    weights = prior.BowshserWeights(side_image.as_array(),num_bowsher_neighbours)\n",
    "    weights = numpy.float32(weights/float(num_bowsher_neighbours))\n",
    "    return weights\n",
    "\n",
    "weights_fdg = update_bowsher_weights(fdg_prior,amyl_init_image,num_bowsher_neighbours)\n",
    "weights_amyl = update_bowsher_weights(amyl_prior,fdg_init_image,num_bowsher_neighbours)\n",
    "\n",
    "# compute indices of the neighbourhood\n",
    "nhoodIndVec_fdg=compute_nhoodIndVec(fdg_init_image,weights_fdg)\n",
    "nhoodIndVec_amyl=compute_nhoodIndVec(amyl_init_image,weights_amyl)\n",
    "\n",
    "def MAPEM_iteration(OSEM_reconstructor,current_image,weights,nhoodIndVec,beta):\n",
    "    image_reg = dePierroReg(current_image.as_array(),weights,nhoodIndVec) # compute xreg\n",
    "    OSEM_reconstructor.update(current_image); # compute EM update\n",
    "    image_EM=current_image.as_array() # get xEM as a numpy array\n",
    "    updated = dePierroUpdate(image_EM, image_reg, beta) # compute new update\n",
    "    current_image.fill(updated) # store for next iteration\n",
    "    return current_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Are we ready?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.1\n",
    "\n",
    "# Final code!\n",
    "\n",
    "# create initial image\n",
    "fdg_obj_fn = get_obj_fun(fdg_sino,fdg_uMap)\n",
    "fdg_reconstructor = get_reconstructor(num_subsets,num_subiters,fdg_obj_fn,fdg_init_image)\n",
    "amyl_obj_fn = get_obj_fun(amyl_sino,amyl_uMap)\n",
    "amyl_reconstructor = get_reconstructor(num_subsets,num_subiters,amyl_obj_fn,amyl_init_image)\n",
    "\n",
    "current_fdg_image = fdg_init_image.clone()\n",
    "current_amyl_image = amyl_init_image.clone()\n",
    "\n",
    "all_images_fdg = numpy.ndarray(shape=(num_subiters+1,) + current_fdg_image.as_array().shape)\n",
    "all_images_amyl = numpy.ndarray(shape=(num_subiters+1,) + current_amyl_image.as_array().shape)\n",
    "\n",
    "all_images_fdg[0,:,:,:] = current_fdg_image.as_array()\n",
    "all_images_amyl[0,:,:,:] = current_amyl_image.as_array()\n",
    "\n",
    "for it in trange(1, num_subiters+1):\n",
    "    # Update FDG weights as fn. of amyloid image\n",
    "    weights_fdg = update_bowsher_weights(fdg_prior,current_amyl_image,num_bowsher_neighbours)\n",
    "\n",
    "    # Do FDG de Pierro update\n",
    "    current_fdg_image = MAPEM_iteration(fdg_reconstructor,current_fdg_image,weights_fdg,nhoodIndVec_fdg,beta)\n",
    "    all_images_fdg[it,:,:,:] = current_fdg_image.as_array()\n",
    "\n",
    "    # Now update the amyloid weights as fn. of FDG image\n",
    "    weights_amyl = update_bowsher_weights(amyl_prior,current_fdg_image,num_bowsher_neighbours)\n",
    "\n",
    "    # And do amyloid de Pierro update\n",
    "    current_amyl_image = MAPEM_iteration(amyl_reconstructor,current_amyl_image,weights_amyl,nhoodIndVec_amyl,beta)\n",
    "    all_images_amyl[it,:,:,:] = current_amyl_image.as_array();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% now call this function to see how we went along\n",
    "plt.figure()\n",
    "subiterations = (1,2,4,8,16,32,42)\n",
    "plot_progress([all_images_fdg],[all_images_amyl], ['FDG MAPEM'], ['Amyloid MAPEM'],subiterations, all_images_fdg.max());"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
