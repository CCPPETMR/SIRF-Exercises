{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of basic PET capabilities with SIRF: IO and projections\n",
    "This demonstration shows how to read images and data, display them. It then\n",
    "illustrates how to use an AcquisitionModel to forward and backproject.\n",
    "\n",
    "This notebook is superseded by the [Introductory/ notebooks](../Introductory/), which illustrate the same concepts with PET, MR and x-ray CT, but kept there are a few differences. \n",
    "- It uses similar images but smaller for speed.\n",
    "- It gives a little bit more information on dimensions of `AcquisitionData`.\n",
    "- For display, it uses the SIRF `show` method and also tells you how to run an animation in Python.\n",
    "\n",
    "This demo is a jupyter notebook, i.e. intended to be run step by step.\n",
    "You could export it as a Python file and run it one go, but that might\n",
    "make little sense as the figures are not labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kris Thielemans  \n",
    "First version: 8th of September 2016  \n",
    "Second version: 17th of May 2018\n",
    "Third version: June 2021\n",
    "\n",
    "CCP PETMR Synergistic Image Reconstruction Framework (SIRF).  \n",
    "Copyright 2015 - 2017 Rutherford Appleton Laboratory STFC.  \n",
    "Copyright 2015 - 2018, 2021 University College London.\n",
    "\n",
    "This is software developed for the Collaborative Computational\n",
    "Project in Positron Emission Tomography and Magnetic Resonance imaging\n",
    "(http://www.ccppetmr.ac.uk/).\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% make sure figures appears inline and animations works\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notebook_setup\n",
    "\n",
    "#%% Initial imports etc\n",
    "import numpy\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import os\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use the 'pet' prefix for all STIR-based SIRF functions\n",
    "# This is done here to explicitly differentiate between SIRF pet functions and \n",
    "# anything else.\n",
    "import sirf.STIR as pet\n",
    "from sirf.Utilities import examples_data_path\n",
    "from sirf_exercises import exercises_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy files to a working folder and change directory to where these files are\n",
    "We do this to avoid cluttering your SIRF files. This way, you can delete \n",
    "`working_folder` and start from scratch.\n",
    "We create that folder in `sirf_exercises_data_path()` but you could change this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find directory with input files\n",
    "org_data_dir=os.path.join(examples_data_path('PET'),'brain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to destination\n",
    "os.chdir(exercises_data_path('PET'))\n",
    "# remove existing files\n",
    "shutil.rmtree('working_folder/brain',True)\n",
    "# copy the whole folder\n",
    "shutil.copytree(org_data_dir,'working_folder/brain')\n",
    "# and go there\n",
    "os.chdir('working_folder/brain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. finally done with initial set-up..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic image manipulations\n",
    "Images (like most other things in SIRF) are represented as *objects*, in this case of type `ImageData`.\n",
    "In practice, this means that you can only manipulate its data via *methods*.\n",
    "\n",
    "Image objects contain the actual voxel values, but also information on the number of voxels,\n",
    "voxel size, etc. There are methods to get this information.\n",
    "\n",
    "There are additional methods for other manipulations, such as basic image arithmetic (e.g.,\n",
    "you can add image objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read in images\n",
    "# Here we will read some images provided with the demo using the ImageData class.\n",
    "# These are in Interfile format. (A text header pointing to a .v file with the binary data).\n",
    "image = pet.ImageData('emission.hv')\n",
    "mu_map = pet.ImageData('attenuation.hv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% What is an ImageData?\n",
    "# Images are represented by objects with several methods. The most important method \n",
    "# is as_array() which we'll use below.\n",
    "# Let's see what all the methods are.\n",
    "help(pet.ImageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show(1,'bla')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Use as_array to extract an array of voxel values\n",
    "# The resulting array as a `numpy` array, as standard in Python.\n",
    "image_array=image.as_array()\n",
    "# We can use the standard `numpy` methods on this array, such as getting its `shape` (i.e. dimensions).\n",
    "print(image_array.shape)\n",
    "# Whenever we want to do something with the image-values, we have to do it via this array.\n",
    "# Let's print a voxel-value.\n",
    "print(image_array[10,40,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Manipulate the image data for illustration\n",
    "# Multiply the data with a factor\n",
    "image_array *= 0.01\n",
    "# Stick this new data into the original image object.\n",
    "# (This will not modify the file content, only the variable in memory.)\n",
    "image.fill(image_array)\n",
    "print(image_array[10,40,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% You can do basic math manipulations with ImageData objects \n",
    "# So the above lines can be done directly on the `image` object\n",
    "image *= 0.01\n",
    "# Let's check\n",
    "image_array=image.as_array()\n",
    "print(image_array[10,40,60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display the middle slice of the image (which is really a 3D volume)\n",
    "\n",
    "# Get the middle slice number\n",
    "slice_num = image_array.shape[0]//2\n",
    "# Display the slice using the `show` method\n",
    "image.show(slice_num, 'emission image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Some other things to do with ImageData objects\n",
    "print(image.voxel_sizes())\n",
    "another_image=image.clone()\n",
    "an_image_with_fixed_values = image.get_uniform_copy(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and back projection\n",
    "Now we will do some PET projections!\n",
    "SIRF uses AcquisitionModel as the object to do forward and back-projections.\n",
    "We will create an AcquisitionModel object and then use it to forward project\n",
    "our image etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Create a SIRF acquisition model\n",
    "# We will use the ray-tracing matrix here as our simple PET model.\n",
    "# There is more to the accquisition model, but that's for another demo.\n",
    "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# Ask STIR to use 5 Lines of Response (LORs) per sinogram-element\n",
    "am.set_num_tangential_LORs(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Specify sinogram dimensions\n",
    "# We need to say what scanner to use, what dimensions etc.\n",
    "# You do this by using existing PET data as a 'template'. \n",
    "# Here, we read a file supplied with the demo as an AcquisitionData object\n",
    "templ = pet.AcquisitionData('template_sinogram.hs')\n",
    "# Now set-up our acquisition model with all information that it needs about the data and image.\n",
    "am.set_up(templ,image); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AcquisitionModel` is now ready for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Do a forward projection of our image\n",
    "# 'forward projection' is the terminology used in PET to simulate the acquisition.\n",
    "# Input is a SIRF ImageData object (not image_array), output is an AcquisitionData object.\n",
    "acquired_data=am.forward(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Check what methods an AcquisitionData object has\n",
    "help(acquired_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AcquisitionData are 4D, organised by time-of-flight (TOF), sinograms, views and radial positions,\n",
    "but there is no TOF here, so the first dimension has size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Let's get the Python array\n",
    "acquisition_array = acquired_data.as_array()\n",
    "print(acquisition_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, this data is very small. That means that future exercises will be fast, but also that resolution is going to be bad..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Display bitmap of the middle sinogram\n",
    "# The sinogram index is the second dimension of an array (but Python counts from 0...)\n",
    "sino_num = acquisition_array.shape[1]//2\n",
    "acquired_data.show(sino_num,title='Forward projection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display some different 'views' in a movie.\n",
    "\n",
    "If the animation doesn't work, you might have to change your \"backend\", e.g. using the `%matplotlib` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitmaps=[]\n",
    "fig=plt.figure()\n",
    "# views are the third index in the data\n",
    "num_views=acquisition_array.shape[2]\n",
    "# first construct all the plots\n",
    "for view in range(0,num_views,4):\n",
    "    bitmap=plt.imshow(acquisition_array[0,:,view,:,])\n",
    "    plt.clim(0,acquisition_array.max())\n",
    "    plt.axis('off')\n",
    "    bitmaps.append([bitmap])\n",
    "# Display as animation\n",
    "ani = animation.ArtistAnimation(fig, bitmaps, interval=100, blit=True, repeat_delay=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might recognise projections of the bottom half of the brain in that animation (with the bottom displayed at the top!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a back-projection.\n",
    "Backprojection uses the transpose of the forward-projection matrix to go from `AcquisitionData` to an `ImageData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprojected = am.backward(acquired_data)\n",
    "# let's display a slice\n",
    "plt.figure()\n",
    "backprojected_array=backprojected.as_array()\n",
    "imshow(backprojected_array[slice_num,:,:],[], 'backprojection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What now?\n",
    "\n",
    "You could try and repeat this with the `brainweb` data, using some of the code of the \"Introductory\" notebooks, and see if you can make sense of the animations, sizes etc.\n",
    "\n",
    "After that, we suggest you try the [image_creation_and_simulation notebook](image_creation_and_simulation.ipynb), which constructs images with geometrical objects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
